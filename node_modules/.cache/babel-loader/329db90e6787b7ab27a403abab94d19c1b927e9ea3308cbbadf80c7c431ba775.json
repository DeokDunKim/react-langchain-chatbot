{"ast":null,"code":"import { Configuration, OpenAIApi } from \"openai\";\nimport { GenerationChunk } from \"../schema/index.js\";\nimport fetchAdapter from \"../util/axios-fetch-adapter.js\";\nimport { getEndpoint } from \"../util/azure.js\";\nimport { getEnvironmentVariable, isNode } from \"../util/env.js\";\nimport { promptLayerTrackRequest } from \"../util/prompt-layer.js\";\nimport { readableStreamToAsyncIterable } from \"../util/stream.js\";\nimport { LLM } from \"./base.js\";\n/**\n * Wrapper around OpenAI large language models that use the Chat endpoint.\n *\n * To use you should have the `openai` package installed, with the\n * `OPENAI_API_KEY` environment variable set.\n *\n * To use with Azure you should have the `openai` package installed, with the\n * `AZURE_OPENAI_API_KEY`,\n * `AZURE_OPENAI_API_INSTANCE_NAME`,\n * `AZURE_OPENAI_API_DEPLOYMENT_NAME`\n * and `AZURE_OPENAI_API_VERSION` environment variable set.\n *\n * @remarks\n * Any parameters that are valid to be passed to {@link\n * https://platform.openai.com/docs/api-reference/chat/create |\n * `openai.createCompletion`} can be passed through {@link modelKwargs}, even\n * if not explicitly available on this class.\n *\n * @augments BaseLLM\n * @augments OpenAIInput\n * @augments AzureOpenAIChatInput\n */\nexport class OpenAIChat extends LLM {\n  static lc_name() {\n    return \"OpenAIChat\";\n  }\n  get callKeys() {\n    return [...super.callKeys, \"options\", \"promptIndex\"];\n  }\n  get lc_secrets() {\n    return {\n      openAIApiKey: \"OPENAI_API_KEY\",\n      azureOpenAIApiKey: \"AZURE_OPENAI_API_KEY\",\n      organization: \"OPENAI_ORGANIZATION\"\n    };\n  }\n  get lc_aliases() {\n    return {\n      modelName: \"model\",\n      openAIApiKey: \"openai_api_key\",\n      azureOpenAIApiVersion: \"azure_openai_api_version\",\n      azureOpenAIApiKey: \"azure_openai_api_key\",\n      azureOpenAIApiInstanceName: \"azure_openai_api_instance_name\",\n      azureOpenAIApiDeploymentName: \"azure_openai_api_deployment_name\"\n    };\n  }\n  constructor(fields, /** @deprecated */\n  configuration) {\n    super(fields ?? {});\n    Object.defineProperty(this, \"lc_serializable\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: true\n    });\n    Object.defineProperty(this, \"temperature\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: 1\n    });\n    Object.defineProperty(this, \"topP\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: 1\n    });\n    Object.defineProperty(this, \"frequencyPenalty\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: 0\n    });\n    Object.defineProperty(this, \"presencePenalty\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: 0\n    });\n    Object.defineProperty(this, \"n\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: 1\n    });\n    Object.defineProperty(this, \"logitBias\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"maxTokens\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"modelName\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: \"gpt-3.5-turbo\"\n    });\n    Object.defineProperty(this, \"prefixMessages\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"modelKwargs\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"timeout\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"stop\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"user\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"streaming\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: false\n    });\n    Object.defineProperty(this, \"openAIApiKey\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"azureOpenAIApiVersion\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"azureOpenAIApiKey\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"azureOpenAIApiInstanceName\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"azureOpenAIApiDeploymentName\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"azureOpenAIBasePath\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"organization\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"client\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"clientConfig\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    this.openAIApiKey = fields?.openAIApiKey ?? getEnvironmentVariable(\"OPENAI_API_KEY\");\n    this.azureOpenAIApiKey = fields?.azureOpenAIApiKey ?? getEnvironmentVariable(\"AZURE_OPENAI_API_KEY\");\n    if (!this.azureOpenAIApiKey && !this.openAIApiKey) {\n      throw new Error(\"OpenAI or Azure OpenAI API key not found\");\n    }\n    this.azureOpenAIApiInstanceName = fields?.azureOpenAIApiInstanceName ?? getEnvironmentVariable(\"AZURE_OPENAI_API_INSTANCE_NAME\");\n    this.azureOpenAIApiDeploymentName = (fields?.azureOpenAIApiCompletionsDeploymentName || fields?.azureOpenAIApiDeploymentName) ?? (getEnvironmentVariable(\"AZURE_OPENAI_API_COMPLETIONS_DEPLOYMENT_NAME\") || getEnvironmentVariable(\"AZURE_OPENAI_API_DEPLOYMENT_NAME\"));\n    this.azureOpenAIApiVersion = fields?.azureOpenAIApiVersion ?? getEnvironmentVariable(\"AZURE_OPENAI_API_VERSION\");\n    this.azureOpenAIBasePath = fields?.azureOpenAIBasePath ?? getEnvironmentVariable(\"AZURE_OPENAI_BASE_PATH\");\n    this.organization = fields?.configuration?.organization ?? getEnvironmentVariable(\"OPENAI_ORGANIZATION\");\n    this.modelName = fields?.modelName ?? this.modelName;\n    this.prefixMessages = fields?.prefixMessages ?? this.prefixMessages;\n    this.modelKwargs = fields?.modelKwargs ?? {};\n    this.timeout = fields?.timeout;\n    this.temperature = fields?.temperature ?? this.temperature;\n    this.topP = fields?.topP ?? this.topP;\n    this.frequencyPenalty = fields?.frequencyPenalty ?? this.frequencyPenalty;\n    this.presencePenalty = fields?.presencePenalty ?? this.presencePenalty;\n    this.n = fields?.n ?? this.n;\n    this.logitBias = fields?.logitBias;\n    this.maxTokens = fields?.maxTokens;\n    this.stop = fields?.stop;\n    this.user = fields?.user;\n    this.streaming = fields?.streaming ?? false;\n    if (this.n > 1) {\n      throw new Error(\"Cannot use n > 1 in OpenAIChat LLM. Use ChatOpenAI Chat Model instead.\");\n    }\n    if (this.azureOpenAIApiKey) {\n      if (!this.azureOpenAIApiInstanceName && !this.azureOpenAIBasePath) {\n        throw new Error(\"Azure OpenAI API instance name not found\");\n      }\n      if (!this.azureOpenAIApiDeploymentName) {\n        throw new Error(\"Azure OpenAI API deployment name not found\");\n      }\n      if (!this.azureOpenAIApiVersion) {\n        throw new Error(\"Azure OpenAI API version not found\");\n      }\n    }\n    this.clientConfig = {\n      apiKey: this.openAIApiKey,\n      organization: this.organization,\n      ...configuration,\n      ...fields?.configuration\n    };\n  }\n  /**\n   * Get the parameters used to invoke the model\n   */\n  invocationParams(options) {\n    return {\n      model: this.modelName,\n      temperature: this.temperature,\n      top_p: this.topP,\n      frequency_penalty: this.frequencyPenalty,\n      presence_penalty: this.presencePenalty,\n      n: this.n,\n      logit_bias: this.logitBias,\n      max_tokens: this.maxTokens === -1 ? undefined : this.maxTokens,\n      stop: options?.stop ?? this.stop,\n      user: this.user,\n      stream: this.streaming,\n      ...this.modelKwargs\n    };\n  }\n  /** @ignore */\n  _identifyingParams() {\n    return {\n      model_name: this.modelName,\n      ...this.invocationParams(),\n      ...this.clientConfig\n    };\n  }\n  /**\n   * Get the identifying parameters for the model\n   */\n  identifyingParams() {\n    return {\n      model_name: this.modelName,\n      ...this.invocationParams(),\n      ...this.clientConfig\n    };\n  }\n  formatMessages(prompt) {\n    const message = {\n      role: \"user\",\n      content: prompt\n    };\n    return this.prefixMessages ? [...this.prefixMessages, message] : [message];\n  }\n  // TODO(jacoblee): Refactor with _generate(..., {stream: true}) implementation\n  // when we integrate OpenAI's new SDK.\n  async *_streamResponseChunks(prompt, options, runManager) {\n    const params = {\n      ...this.invocationParams(options),\n      messages: this.formatMessages(prompt),\n      stream: true\n    };\n    const streamIterable = this.startStream(params, options);\n    for await (const streamedResponse of streamIterable) {\n      const data = JSON.parse(streamedResponse);\n      const choice = data.choices?.[0];\n      if (!choice) {\n        continue;\n      }\n      const {\n        delta\n      } = choice;\n      const generationChunk = new GenerationChunk({\n        text: delta.content ?? \"\"\n      });\n      yield generationChunk;\n      // eslint-disable-next-line no-void\n      void runManager?.handleLLMNewToken(generationChunk.text ?? \"\");\n    }\n  }\n  startStream(request, options) {\n    let done = false;\n    const stream = new TransformStream();\n    const writer = stream.writable.getWriter();\n    const iterable = readableStreamToAsyncIterable(stream.readable);\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    let err;\n    this.completionWithRetry(request, {\n      ...options,\n      adapter: fetchAdapter,\n      responseType: \"stream\",\n      onmessage: event => {\n        if (done) return;\n        if (event.data?.trim?.() === \"[DONE]\") {\n          done = true;\n          // eslint-disable-next-line no-void\n          void writer.close();\n        } else {\n          const data = JSON.parse(event.data);\n          if (data.error) {\n            done = true;\n            throw data.error;\n          }\n          // eslint-disable-next-line no-void\n          void writer.write(event.data);\n        }\n      }\n    }).catch(error => {\n      if (!done) {\n        err = error;\n        done = true;\n        // eslint-disable-next-line no-void\n        void writer.close();\n      }\n    });\n    return {\n      async next() {\n        const chunk = await iterable.next();\n        if (err) {\n          throw err;\n        }\n        return chunk;\n      },\n      [Symbol.asyncIterator]() {\n        return this;\n      }\n    };\n  }\n  /** @ignore */\n  async _call(prompt, options, runManager) {\n    const params = this.invocationParams(options);\n    const data = params.stream ? await new Promise((resolve, reject) => {\n      let response;\n      let rejected = false;\n      let resolved = false;\n      this.completionWithRetry({\n        ...params,\n        messages: this.formatMessages(prompt)\n      }, {\n        signal: options.signal,\n        ...options.options,\n        adapter: fetchAdapter,\n        responseType: \"stream\",\n        onmessage: event => {\n          if (event.data?.trim?.() === \"[DONE]\") {\n            if (resolved || rejected) {\n              return;\n            }\n            resolved = true;\n            resolve(response);\n          } else {\n            const data = JSON.parse(event.data);\n            if (data?.error) {\n              if (rejected) {\n                return;\n              }\n              rejected = true;\n              reject(data.error);\n              return;\n            }\n            const message = data;\n            // on the first message set the response properties\n            if (!response) {\n              response = {\n                id: message.id,\n                object: message.object,\n                created: message.created,\n                model: message.model,\n                choices: []\n              };\n            }\n            // on all messages, update choice\n            for (const part of message.choices) {\n              if (part != null) {\n                let choice = response.choices.find(c => c.index === part.index);\n                if (!choice) {\n                  choice = {\n                    index: part.index,\n                    finish_reason: part.finish_reason ?? undefined\n                  };\n                  response.choices.push(choice);\n                }\n                if (!choice.message) {\n                  choice.message = {\n                    role: part.delta?.role,\n                    content: part.delta?.content ?? \"\"\n                  };\n                }\n                choice.message.content += part.delta?.content ?? \"\";\n                // eslint-disable-next-line no-void\n                void runManager?.handleLLMNewToken(part.delta?.content ?? \"\", {\n                  prompt: options.promptIndex ?? 0,\n                  completion: part.index\n                });\n              }\n            }\n            // when all messages are finished, resolve\n            if (!resolved && !rejected && message.choices.every(c => c.finish_reason != null)) {\n              resolved = true;\n              resolve(response);\n            }\n          }\n        }\n      }).catch(error => {\n        if (!rejected) {\n          rejected = true;\n          reject(error);\n        }\n      });\n    }) : await this.completionWithRetry({\n      ...params,\n      messages: this.formatMessages(prompt)\n    }, {\n      signal: options.signal,\n      ...options.options\n    });\n    return data.choices[0].message?.content ?? \"\";\n  }\n  /** @ignore */\n  async completionWithRetry(request, options) {\n    if (!this.client) {\n      const openAIEndpointConfig = {\n        azureOpenAIApiDeploymentName: this.azureOpenAIApiDeploymentName,\n        azureOpenAIApiInstanceName: this.azureOpenAIApiInstanceName,\n        azureOpenAIApiKey: this.azureOpenAIApiKey,\n        azureOpenAIBasePath: this.azureOpenAIBasePath,\n        basePath: this.clientConfig.basePath\n      };\n      const endpoint = getEndpoint(openAIEndpointConfig);\n      const clientConfig = new Configuration({\n        ...this.clientConfig,\n        basePath: endpoint,\n        baseOptions: {\n          timeout: this.timeout,\n          ...this.clientConfig.baseOptions\n        }\n      });\n      this.client = new OpenAIApi(clientConfig);\n    }\n    const axiosOptions = {\n      adapter: isNode() ? undefined : fetchAdapter,\n      ...this.clientConfig.baseOptions,\n      ...options\n    };\n    if (this.azureOpenAIApiKey) {\n      axiosOptions.headers = {\n        \"api-key\": this.azureOpenAIApiKey,\n        ...axiosOptions.headers\n      };\n      axiosOptions.params = {\n        \"api-version\": this.azureOpenAIApiVersion,\n        ...axiosOptions.params\n      };\n    }\n    return this.caller.call(this.client.createChatCompletion.bind(this.client), request, axiosOptions).then(res => res.data);\n  }\n  _llmType() {\n    return \"openai\";\n  }\n}\n/**\n * PromptLayer wrapper to OpenAIChat\n */\nexport class PromptLayerOpenAIChat extends OpenAIChat {\n  get lc_secrets() {\n    return {\n      promptLayerApiKey: \"PROMPTLAYER_API_KEY\"\n    };\n  }\n  constructor(fields) {\n    super(fields);\n    Object.defineProperty(this, \"lc_serializable\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: false\n    });\n    Object.defineProperty(this, \"promptLayerApiKey\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"plTags\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"returnPromptLayerId\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    this.plTags = fields?.plTags ?? [];\n    this.returnPromptLayerId = fields?.returnPromptLayerId ?? false;\n    this.promptLayerApiKey = fields?.promptLayerApiKey ?? getEnvironmentVariable(\"PROMPTLAYER_API_KEY\");\n    if (!this.promptLayerApiKey) {\n      throw new Error(\"Missing PromptLayer API key\");\n    }\n  }\n  async completionWithRetry(request, options) {\n    if (request.stream) {\n      return super.completionWithRetry(request, options);\n    }\n    const response = await super.completionWithRetry(request);\n    return response;\n  }\n  async _generate(prompts, options, runManager) {\n    let choice;\n    const generations = await Promise.all(prompts.map(async prompt => {\n      const requestStartTime = Date.now();\n      const text = await this._call(prompt, options, runManager);\n      const requestEndTime = Date.now();\n      choice = [{\n        text\n      }];\n      const parsedResp = {\n        text\n      };\n      const promptLayerRespBody = await promptLayerTrackRequest(this.caller, \"langchain.PromptLayerOpenAIChat\", [prompt], this._identifyingParams(), this.plTags, parsedResp, requestStartTime, requestEndTime, this.promptLayerApiKey);\n      if (this.returnPromptLayerId === true && promptLayerRespBody.success === true) {\n        choice[0].generationInfo = {\n          promptLayerRequestId: promptLayerRespBody.request_id\n        };\n      }\n      return choice;\n    }));\n    return {\n      generations\n    };\n  }\n}","map":{"version":3,"names":["Configuration","OpenAIApi","GenerationChunk","fetchAdapter","getEndpoint","getEnvironmentVariable","isNode","promptLayerTrackRequest","readableStreamToAsyncIterable","LLM","OpenAIChat","lc_name","callKeys","lc_secrets","openAIApiKey","azureOpenAIApiKey","organization","lc_aliases","modelName","azureOpenAIApiVersion","azureOpenAIApiInstanceName","azureOpenAIApiDeploymentName","constructor","fields","configuration","Object","defineProperty","enumerable","configurable","writable","value","Error","azureOpenAIApiCompletionsDeploymentName","azureOpenAIBasePath","prefixMessages","modelKwargs","timeout","temperature","topP","frequencyPenalty","presencePenalty","n","logitBias","maxTokens","stop","user","streaming","clientConfig","apiKey","invocationParams","options","model","top_p","frequency_penalty","presence_penalty","logit_bias","max_tokens","undefined","stream","_identifyingParams","model_name","identifyingParams","formatMessages","prompt","message","role","content","_streamResponseChunks","runManager","params","messages","streamIterable","startStream","streamedResponse","data","JSON","parse","choice","choices","delta","generationChunk","text","handleLLMNewToken","request","done","TransformStream","writer","getWriter","iterable","readable","err","completionWithRetry","adapter","responseType","onmessage","event","trim","close","error","write","catch","next","chunk","Symbol","asyncIterator","_call","Promise","resolve","reject","response","rejected","resolved","signal","id","object","created","part","find","c","index","finish_reason","push","promptIndex","completion","every","client","openAIEndpointConfig","basePath","endpoint","baseOptions","axiosOptions","headers","caller","call","createChatCompletion","bind","then","res","_llmType","PromptLayerOpenAIChat","promptLayerApiKey","plTags","returnPromptLayerId","_generate","prompts","generations","all","map","requestStartTime","Date","now","requestEndTime","parsedResp","promptLayerRespBody","success","generationInfo","promptLayerRequestId","request_id"],"sources":["/Users/idasilfverskiold/gptSandbox/reactlangchain/sandbox/node_modules/langchain/dist/llms/openai-chat.js"],"sourcesContent":["import { Configuration, OpenAIApi, } from \"openai\";\nimport { GenerationChunk } from \"../schema/index.js\";\nimport fetchAdapter from \"../util/axios-fetch-adapter.js\";\nimport { getEndpoint } from \"../util/azure.js\";\nimport { getEnvironmentVariable, isNode } from \"../util/env.js\";\nimport { promptLayerTrackRequest } from \"../util/prompt-layer.js\";\nimport { readableStreamToAsyncIterable } from \"../util/stream.js\";\nimport { LLM } from \"./base.js\";\n/**\n * Wrapper around OpenAI large language models that use the Chat endpoint.\n *\n * To use you should have the `openai` package installed, with the\n * `OPENAI_API_KEY` environment variable set.\n *\n * To use with Azure you should have the `openai` package installed, with the\n * `AZURE_OPENAI_API_KEY`,\n * `AZURE_OPENAI_API_INSTANCE_NAME`,\n * `AZURE_OPENAI_API_DEPLOYMENT_NAME`\n * and `AZURE_OPENAI_API_VERSION` environment variable set.\n *\n * @remarks\n * Any parameters that are valid to be passed to {@link\n * https://platform.openai.com/docs/api-reference/chat/create |\n * `openai.createCompletion`} can be passed through {@link modelKwargs}, even\n * if not explicitly available on this class.\n *\n * @augments BaseLLM\n * @augments OpenAIInput\n * @augments AzureOpenAIChatInput\n */\nexport class OpenAIChat extends LLM {\n    static lc_name() {\n        return \"OpenAIChat\";\n    }\n    get callKeys() {\n        return [\n            ...super.callKeys,\n            \"options\",\n            \"promptIndex\",\n        ];\n    }\n    get lc_secrets() {\n        return {\n            openAIApiKey: \"OPENAI_API_KEY\",\n            azureOpenAIApiKey: \"AZURE_OPENAI_API_KEY\",\n            organization: \"OPENAI_ORGANIZATION\",\n        };\n    }\n    get lc_aliases() {\n        return {\n            modelName: \"model\",\n            openAIApiKey: \"openai_api_key\",\n            azureOpenAIApiVersion: \"azure_openai_api_version\",\n            azureOpenAIApiKey: \"azure_openai_api_key\",\n            azureOpenAIApiInstanceName: \"azure_openai_api_instance_name\",\n            azureOpenAIApiDeploymentName: \"azure_openai_api_deployment_name\",\n        };\n    }\n    constructor(fields, \n    /** @deprecated */\n    configuration) {\n        super(fields ?? {});\n        Object.defineProperty(this, \"lc_serializable\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: true\n        });\n        Object.defineProperty(this, \"temperature\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 1\n        });\n        Object.defineProperty(this, \"topP\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 1\n        });\n        Object.defineProperty(this, \"frequencyPenalty\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 0\n        });\n        Object.defineProperty(this, \"presencePenalty\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 0\n        });\n        Object.defineProperty(this, \"n\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 1\n        });\n        Object.defineProperty(this, \"logitBias\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"maxTokens\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"modelName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"gpt-3.5-turbo\"\n        });\n        Object.defineProperty(this, \"prefixMessages\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"modelKwargs\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"timeout\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"stop\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"user\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"streaming\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n        Object.defineProperty(this, \"openAIApiKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"azureOpenAIApiVersion\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"azureOpenAIApiKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"azureOpenAIApiInstanceName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"azureOpenAIApiDeploymentName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"azureOpenAIBasePath\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"organization\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"client\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"clientConfig\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.openAIApiKey =\n            fields?.openAIApiKey ?? getEnvironmentVariable(\"OPENAI_API_KEY\");\n        this.azureOpenAIApiKey =\n            fields?.azureOpenAIApiKey ??\n                getEnvironmentVariable(\"AZURE_OPENAI_API_KEY\");\n        if (!this.azureOpenAIApiKey && !this.openAIApiKey) {\n            throw new Error(\"OpenAI or Azure OpenAI API key not found\");\n        }\n        this.azureOpenAIApiInstanceName =\n            fields?.azureOpenAIApiInstanceName ??\n                getEnvironmentVariable(\"AZURE_OPENAI_API_INSTANCE_NAME\");\n        this.azureOpenAIApiDeploymentName =\n            (fields?.azureOpenAIApiCompletionsDeploymentName ||\n                fields?.azureOpenAIApiDeploymentName) ??\n                (getEnvironmentVariable(\"AZURE_OPENAI_API_COMPLETIONS_DEPLOYMENT_NAME\") ||\n                    getEnvironmentVariable(\"AZURE_OPENAI_API_DEPLOYMENT_NAME\"));\n        this.azureOpenAIApiVersion =\n            fields?.azureOpenAIApiVersion ??\n                getEnvironmentVariable(\"AZURE_OPENAI_API_VERSION\");\n        this.azureOpenAIBasePath =\n            fields?.azureOpenAIBasePath ??\n                getEnvironmentVariable(\"AZURE_OPENAI_BASE_PATH\");\n        this.organization =\n            fields?.configuration?.organization ??\n                getEnvironmentVariable(\"OPENAI_ORGANIZATION\");\n        this.modelName = fields?.modelName ?? this.modelName;\n        this.prefixMessages = fields?.prefixMessages ?? this.prefixMessages;\n        this.modelKwargs = fields?.modelKwargs ?? {};\n        this.timeout = fields?.timeout;\n        this.temperature = fields?.temperature ?? this.temperature;\n        this.topP = fields?.topP ?? this.topP;\n        this.frequencyPenalty = fields?.frequencyPenalty ?? this.frequencyPenalty;\n        this.presencePenalty = fields?.presencePenalty ?? this.presencePenalty;\n        this.n = fields?.n ?? this.n;\n        this.logitBias = fields?.logitBias;\n        this.maxTokens = fields?.maxTokens;\n        this.stop = fields?.stop;\n        this.user = fields?.user;\n        this.streaming = fields?.streaming ?? false;\n        if (this.n > 1) {\n            throw new Error(\"Cannot use n > 1 in OpenAIChat LLM. Use ChatOpenAI Chat Model instead.\");\n        }\n        if (this.azureOpenAIApiKey) {\n            if (!this.azureOpenAIApiInstanceName && !this.azureOpenAIBasePath) {\n                throw new Error(\"Azure OpenAI API instance name not found\");\n            }\n            if (!this.azureOpenAIApiDeploymentName) {\n                throw new Error(\"Azure OpenAI API deployment name not found\");\n            }\n            if (!this.azureOpenAIApiVersion) {\n                throw new Error(\"Azure OpenAI API version not found\");\n            }\n        }\n        this.clientConfig = {\n            apiKey: this.openAIApiKey,\n            organization: this.organization,\n            ...configuration,\n            ...fields?.configuration,\n        };\n    }\n    /**\n     * Get the parameters used to invoke the model\n     */\n    invocationParams(options) {\n        return {\n            model: this.modelName,\n            temperature: this.temperature,\n            top_p: this.topP,\n            frequency_penalty: this.frequencyPenalty,\n            presence_penalty: this.presencePenalty,\n            n: this.n,\n            logit_bias: this.logitBias,\n            max_tokens: this.maxTokens === -1 ? undefined : this.maxTokens,\n            stop: options?.stop ?? this.stop,\n            user: this.user,\n            stream: this.streaming,\n            ...this.modelKwargs,\n        };\n    }\n    /** @ignore */\n    _identifyingParams() {\n        return {\n            model_name: this.modelName,\n            ...this.invocationParams(),\n            ...this.clientConfig,\n        };\n    }\n    /**\n     * Get the identifying parameters for the model\n     */\n    identifyingParams() {\n        return {\n            model_name: this.modelName,\n            ...this.invocationParams(),\n            ...this.clientConfig,\n        };\n    }\n    formatMessages(prompt) {\n        const message = {\n            role: \"user\",\n            content: prompt,\n        };\n        return this.prefixMessages ? [...this.prefixMessages, message] : [message];\n    }\n    // TODO(jacoblee): Refactor with _generate(..., {stream: true}) implementation\n    // when we integrate OpenAI's new SDK.\n    async *_streamResponseChunks(prompt, options, runManager) {\n        const params = {\n            ...this.invocationParams(options),\n            messages: this.formatMessages(prompt),\n            stream: true,\n        };\n        const streamIterable = this.startStream(params, options);\n        for await (const streamedResponse of streamIterable) {\n            const data = JSON.parse(streamedResponse);\n            const choice = data.choices?.[0];\n            if (!choice) {\n                continue;\n            }\n            const { delta } = choice;\n            const generationChunk = new GenerationChunk({\n                text: delta.content ?? \"\",\n            });\n            yield generationChunk;\n            // eslint-disable-next-line no-void\n            void runManager?.handleLLMNewToken(generationChunk.text ?? \"\");\n        }\n    }\n    startStream(request, options) {\n        let done = false;\n        const stream = new TransformStream();\n        const writer = stream.writable.getWriter();\n        const iterable = readableStreamToAsyncIterable(stream.readable);\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        let err;\n        this.completionWithRetry(request, {\n            ...options,\n            adapter: fetchAdapter,\n            responseType: \"stream\",\n            onmessage: (event) => {\n                if (done)\n                    return;\n                if (event.data?.trim?.() === \"[DONE]\") {\n                    done = true;\n                    // eslint-disable-next-line no-void\n                    void writer.close();\n                }\n                else {\n                    const data = JSON.parse(event.data);\n                    if (data.error) {\n                        done = true;\n                        throw data.error;\n                    }\n                    // eslint-disable-next-line no-void\n                    void writer.write(event.data);\n                }\n            },\n        }).catch((error) => {\n            if (!done) {\n                err = error;\n                done = true;\n                // eslint-disable-next-line no-void\n                void writer.close();\n            }\n        });\n        return {\n            async next() {\n                const chunk = await iterable.next();\n                if (err) {\n                    throw err;\n                }\n                return chunk;\n            },\n            [Symbol.asyncIterator]() {\n                return this;\n            },\n        };\n    }\n    /** @ignore */\n    async _call(prompt, options, runManager) {\n        const params = this.invocationParams(options);\n        const data = params.stream\n            ? await new Promise((resolve, reject) => {\n                let response;\n                let rejected = false;\n                let resolved = false;\n                this.completionWithRetry({\n                    ...params,\n                    messages: this.formatMessages(prompt),\n                }, {\n                    signal: options.signal,\n                    ...options.options,\n                    adapter: fetchAdapter,\n                    responseType: \"stream\",\n                    onmessage: (event) => {\n                        if (event.data?.trim?.() === \"[DONE]\") {\n                            if (resolved || rejected) {\n                                return;\n                            }\n                            resolved = true;\n                            resolve(response);\n                        }\n                        else {\n                            const data = JSON.parse(event.data);\n                            if (data?.error) {\n                                if (rejected) {\n                                    return;\n                                }\n                                rejected = true;\n                                reject(data.error);\n                                return;\n                            }\n                            const message = data;\n                            // on the first message set the response properties\n                            if (!response) {\n                                response = {\n                                    id: message.id,\n                                    object: message.object,\n                                    created: message.created,\n                                    model: message.model,\n                                    choices: [],\n                                };\n                            }\n                            // on all messages, update choice\n                            for (const part of message.choices) {\n                                if (part != null) {\n                                    let choice = response.choices.find((c) => c.index === part.index);\n                                    if (!choice) {\n                                        choice = {\n                                            index: part.index,\n                                            finish_reason: part.finish_reason ?? undefined,\n                                        };\n                                        response.choices.push(choice);\n                                    }\n                                    if (!choice.message) {\n                                        choice.message = {\n                                            role: part.delta\n                                                ?.role,\n                                            content: part.delta?.content ?? \"\",\n                                        };\n                                    }\n                                    choice.message.content += part.delta?.content ?? \"\";\n                                    // eslint-disable-next-line no-void\n                                    void runManager?.handleLLMNewToken(part.delta?.content ?? \"\", {\n                                        prompt: options.promptIndex ?? 0,\n                                        completion: part.index,\n                                    });\n                                }\n                            }\n                            // when all messages are finished, resolve\n                            if (!resolved &&\n                                !rejected &&\n                                message.choices.every((c) => c.finish_reason != null)) {\n                                resolved = true;\n                                resolve(response);\n                            }\n                        }\n                    },\n                }).catch((error) => {\n                    if (!rejected) {\n                        rejected = true;\n                        reject(error);\n                    }\n                });\n            })\n            : await this.completionWithRetry({\n                ...params,\n                messages: this.formatMessages(prompt),\n            }, {\n                signal: options.signal,\n                ...options.options,\n            });\n        return data.choices[0].message?.content ?? \"\";\n    }\n    /** @ignore */\n    async completionWithRetry(request, options) {\n        if (!this.client) {\n            const openAIEndpointConfig = {\n                azureOpenAIApiDeploymentName: this.azureOpenAIApiDeploymentName,\n                azureOpenAIApiInstanceName: this.azureOpenAIApiInstanceName,\n                azureOpenAIApiKey: this.azureOpenAIApiKey,\n                azureOpenAIBasePath: this.azureOpenAIBasePath,\n                basePath: this.clientConfig.basePath,\n            };\n            const endpoint = getEndpoint(openAIEndpointConfig);\n            const clientConfig = new Configuration({\n                ...this.clientConfig,\n                basePath: endpoint,\n                baseOptions: {\n                    timeout: this.timeout,\n                    ...this.clientConfig.baseOptions,\n                },\n            });\n            this.client = new OpenAIApi(clientConfig);\n        }\n        const axiosOptions = {\n            adapter: isNode() ? undefined : fetchAdapter,\n            ...this.clientConfig.baseOptions,\n            ...options,\n        };\n        if (this.azureOpenAIApiKey) {\n            axiosOptions.headers = {\n                \"api-key\": this.azureOpenAIApiKey,\n                ...axiosOptions.headers,\n            };\n            axiosOptions.params = {\n                \"api-version\": this.azureOpenAIApiVersion,\n                ...axiosOptions.params,\n            };\n        }\n        return this.caller\n            .call(this.client.createChatCompletion.bind(this.client), request, axiosOptions)\n            .then((res) => res.data);\n    }\n    _llmType() {\n        return \"openai\";\n    }\n}\n/**\n * PromptLayer wrapper to OpenAIChat\n */\nexport class PromptLayerOpenAIChat extends OpenAIChat {\n    get lc_secrets() {\n        return {\n            promptLayerApiKey: \"PROMPTLAYER_API_KEY\",\n        };\n    }\n    constructor(fields) {\n        super(fields);\n        Object.defineProperty(this, \"lc_serializable\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n        Object.defineProperty(this, \"promptLayerApiKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"plTags\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"returnPromptLayerId\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.plTags = fields?.plTags ?? [];\n        this.returnPromptLayerId = fields?.returnPromptLayerId ?? false;\n        this.promptLayerApiKey =\n            fields?.promptLayerApiKey ??\n                getEnvironmentVariable(\"PROMPTLAYER_API_KEY\");\n        if (!this.promptLayerApiKey) {\n            throw new Error(\"Missing PromptLayer API key\");\n        }\n    }\n    async completionWithRetry(request, options) {\n        if (request.stream) {\n            return super.completionWithRetry(request, options);\n        }\n        const response = await super.completionWithRetry(request);\n        return response;\n    }\n    async _generate(prompts, options, runManager) {\n        let choice;\n        const generations = await Promise.all(prompts.map(async (prompt) => {\n            const requestStartTime = Date.now();\n            const text = await this._call(prompt, options, runManager);\n            const requestEndTime = Date.now();\n            choice = [{ text }];\n            const parsedResp = {\n                text,\n            };\n            const promptLayerRespBody = await promptLayerTrackRequest(this.caller, \"langchain.PromptLayerOpenAIChat\", [prompt], this._identifyingParams(), this.plTags, parsedResp, requestStartTime, requestEndTime, this.promptLayerApiKey);\n            if (this.returnPromptLayerId === true &&\n                promptLayerRespBody.success === true) {\n                choice[0].generationInfo = {\n                    promptLayerRequestId: promptLayerRespBody.request_id,\n                };\n            }\n            return choice;\n        }));\n        return { generations };\n    }\n}\n"],"mappings":"AAAA,SAASA,aAAa,EAAEC,SAAS,QAAS,QAAQ;AAClD,SAASC,eAAe,QAAQ,oBAAoB;AACpD,OAAOC,YAAY,MAAM,gCAAgC;AACzD,SAASC,WAAW,QAAQ,kBAAkB;AAC9C,SAASC,sBAAsB,EAAEC,MAAM,QAAQ,gBAAgB;AAC/D,SAASC,uBAAuB,QAAQ,yBAAyB;AACjE,SAASC,6BAA6B,QAAQ,mBAAmB;AACjE,SAASC,GAAG,QAAQ,WAAW;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMC,UAAU,SAASD,GAAG,CAAC;EAChC,OAAOE,OAAOA,CAAA,EAAG;IACb,OAAO,YAAY;EACvB;EACA,IAAIC,QAAQA,CAAA,EAAG;IACX,OAAO,CACH,GAAG,KAAK,CAACA,QAAQ,EACjB,SAAS,EACT,aAAa,CAChB;EACL;EACA,IAAIC,UAAUA,CAAA,EAAG;IACb,OAAO;MACHC,YAAY,EAAE,gBAAgB;MAC9BC,iBAAiB,EAAE,sBAAsB;MACzCC,YAAY,EAAE;IAClB,CAAC;EACL;EACA,IAAIC,UAAUA,CAAA,EAAG;IACb,OAAO;MACHC,SAAS,EAAE,OAAO;MAClBJ,YAAY,EAAE,gBAAgB;MAC9BK,qBAAqB,EAAE,0BAA0B;MACjDJ,iBAAiB,EAAE,sBAAsB;MACzCK,0BAA0B,EAAE,gCAAgC;MAC5DC,4BAA4B,EAAE;IAClC,CAAC;EACL;EACAC,WAAWA,CAACC,MAAM,EAClB;EACAC,aAAa,EAAE;IACX,KAAK,CAACD,MAAM,IAAI,CAAC,CAAC,CAAC;IACnBE,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,iBAAiB,EAAE;MAC3CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,aAAa,EAAE;MACvCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,MAAM,EAAE;MAChCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,kBAAkB,EAAE;MAC5CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,iBAAiB,EAAE;MAC3CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,GAAG,EAAE;MAC7BC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,WAAW,EAAE;MACrCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,WAAW,EAAE;MACrCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,WAAW,EAAE;MACrCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,gBAAgB,EAAE;MAC1CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,aAAa,EAAE;MACvCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,SAAS,EAAE;MACnCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,MAAM,EAAE;MAChCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,MAAM,EAAE;MAChCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,WAAW,EAAE;MACrCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,cAAc,EAAE;MACxCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,uBAAuB,EAAE;MACjDC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,mBAAmB,EAAE;MAC7CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,4BAA4B,EAAE;MACtDC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,8BAA8B,EAAE;MACxDC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,qBAAqB,EAAE;MAC/CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,cAAc,EAAE;MACxCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,QAAQ,EAAE;MAClCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,cAAc,EAAE;MACxCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACF,IAAI,CAAChB,YAAY,GACbS,MAAM,EAAET,YAAY,IAAIT,sBAAsB,CAAC,gBAAgB,CAAC;IACpE,IAAI,CAACU,iBAAiB,GAClBQ,MAAM,EAAER,iBAAiB,IACrBV,sBAAsB,CAAC,sBAAsB,CAAC;IACtD,IAAI,CAAC,IAAI,CAACU,iBAAiB,IAAI,CAAC,IAAI,CAACD,YAAY,EAAE;MAC/C,MAAM,IAAIiB,KAAK,CAAC,0CAA0C,CAAC;IAC/D;IACA,IAAI,CAACX,0BAA0B,GAC3BG,MAAM,EAAEH,0BAA0B,IAC9Bf,sBAAsB,CAAC,gCAAgC,CAAC;IAChE,IAAI,CAACgB,4BAA4B,GAC7B,CAACE,MAAM,EAAES,uCAAuC,IAC5CT,MAAM,EAAEF,4BAA4B,MACnChB,sBAAsB,CAAC,8CAA8C,CAAC,IACnEA,sBAAsB,CAAC,kCAAkC,CAAC,CAAC;IACvE,IAAI,CAACc,qBAAqB,GACtBI,MAAM,EAAEJ,qBAAqB,IACzBd,sBAAsB,CAAC,0BAA0B,CAAC;IAC1D,IAAI,CAAC4B,mBAAmB,GACpBV,MAAM,EAAEU,mBAAmB,IACvB5B,sBAAsB,CAAC,wBAAwB,CAAC;IACxD,IAAI,CAACW,YAAY,GACbO,MAAM,EAAEC,aAAa,EAAER,YAAY,IAC/BX,sBAAsB,CAAC,qBAAqB,CAAC;IACrD,IAAI,CAACa,SAAS,GAAGK,MAAM,EAAEL,SAAS,IAAI,IAAI,CAACA,SAAS;IACpD,IAAI,CAACgB,cAAc,GAAGX,MAAM,EAAEW,cAAc,IAAI,IAAI,CAACA,cAAc;IACnE,IAAI,CAACC,WAAW,GAAGZ,MAAM,EAAEY,WAAW,IAAI,CAAC,CAAC;IAC5C,IAAI,CAACC,OAAO,GAAGb,MAAM,EAAEa,OAAO;IAC9B,IAAI,CAACC,WAAW,GAAGd,MAAM,EAAEc,WAAW,IAAI,IAAI,CAACA,WAAW;IAC1D,IAAI,CAACC,IAAI,GAAGf,MAAM,EAAEe,IAAI,IAAI,IAAI,CAACA,IAAI;IACrC,IAAI,CAACC,gBAAgB,GAAGhB,MAAM,EAAEgB,gBAAgB,IAAI,IAAI,CAACA,gBAAgB;IACzE,IAAI,CAACC,eAAe,GAAGjB,MAAM,EAAEiB,eAAe,IAAI,IAAI,CAACA,eAAe;IACtE,IAAI,CAACC,CAAC,GAAGlB,MAAM,EAAEkB,CAAC,IAAI,IAAI,CAACA,CAAC;IAC5B,IAAI,CAACC,SAAS,GAAGnB,MAAM,EAAEmB,SAAS;IAClC,IAAI,CAACC,SAAS,GAAGpB,MAAM,EAAEoB,SAAS;IAClC,IAAI,CAACC,IAAI,GAAGrB,MAAM,EAAEqB,IAAI;IACxB,IAAI,CAACC,IAAI,GAAGtB,MAAM,EAAEsB,IAAI;IACxB,IAAI,CAACC,SAAS,GAAGvB,MAAM,EAAEuB,SAAS,IAAI,KAAK;IAC3C,IAAI,IAAI,CAACL,CAAC,GAAG,CAAC,EAAE;MACZ,MAAM,IAAIV,KAAK,CAAC,wEAAwE,CAAC;IAC7F;IACA,IAAI,IAAI,CAAChB,iBAAiB,EAAE;MACxB,IAAI,CAAC,IAAI,CAACK,0BAA0B,IAAI,CAAC,IAAI,CAACa,mBAAmB,EAAE;QAC/D,MAAM,IAAIF,KAAK,CAAC,0CAA0C,CAAC;MAC/D;MACA,IAAI,CAAC,IAAI,CAACV,4BAA4B,EAAE;QACpC,MAAM,IAAIU,KAAK,CAAC,4CAA4C,CAAC;MACjE;MACA,IAAI,CAAC,IAAI,CAACZ,qBAAqB,EAAE;QAC7B,MAAM,IAAIY,KAAK,CAAC,oCAAoC,CAAC;MACzD;IACJ;IACA,IAAI,CAACgB,YAAY,GAAG;MAChBC,MAAM,EAAE,IAAI,CAAClC,YAAY;MACzBE,YAAY,EAAE,IAAI,CAACA,YAAY;MAC/B,GAAGQ,aAAa;MAChB,GAAGD,MAAM,EAAEC;IACf,CAAC;EACL;EACA;AACJ;AACA;EACIyB,gBAAgBA,CAACC,OAAO,EAAE;IACtB,OAAO;MACHC,KAAK,EAAE,IAAI,CAACjC,SAAS;MACrBmB,WAAW,EAAE,IAAI,CAACA,WAAW;MAC7Be,KAAK,EAAE,IAAI,CAACd,IAAI;MAChBe,iBAAiB,EAAE,IAAI,CAACd,gBAAgB;MACxCe,gBAAgB,EAAE,IAAI,CAACd,eAAe;MACtCC,CAAC,EAAE,IAAI,CAACA,CAAC;MACTc,UAAU,EAAE,IAAI,CAACb,SAAS;MAC1Bc,UAAU,EAAE,IAAI,CAACb,SAAS,KAAK,CAAC,CAAC,GAAGc,SAAS,GAAG,IAAI,CAACd,SAAS;MAC9DC,IAAI,EAAEM,OAAO,EAAEN,IAAI,IAAI,IAAI,CAACA,IAAI;MAChCC,IAAI,EAAE,IAAI,CAACA,IAAI;MACfa,MAAM,EAAE,IAAI,CAACZ,SAAS;MACtB,GAAG,IAAI,CAACX;IACZ,CAAC;EACL;EACA;EACAwB,kBAAkBA,CAAA,EAAG;IACjB,OAAO;MACHC,UAAU,EAAE,IAAI,CAAC1C,SAAS;MAC1B,GAAG,IAAI,CAAC+B,gBAAgB,CAAC,CAAC;MAC1B,GAAG,IAAI,CAACF;IACZ,CAAC;EACL;EACA;AACJ;AACA;EACIc,iBAAiBA,CAAA,EAAG;IAChB,OAAO;MACHD,UAAU,EAAE,IAAI,CAAC1C,SAAS;MAC1B,GAAG,IAAI,CAAC+B,gBAAgB,CAAC,CAAC;MAC1B,GAAG,IAAI,CAACF;IACZ,CAAC;EACL;EACAe,cAAcA,CAACC,MAAM,EAAE;IACnB,MAAMC,OAAO,GAAG;MACZC,IAAI,EAAE,MAAM;MACZC,OAAO,EAAEH;IACb,CAAC;IACD,OAAO,IAAI,CAAC7B,cAAc,GAAG,CAAC,GAAG,IAAI,CAACA,cAAc,EAAE8B,OAAO,CAAC,GAAG,CAACA,OAAO,CAAC;EAC9E;EACA;EACA;EACA,OAAOG,qBAAqBA,CAACJ,MAAM,EAAEb,OAAO,EAAEkB,UAAU,EAAE;IACtD,MAAMC,MAAM,GAAG;MACX,GAAG,IAAI,CAACpB,gBAAgB,CAACC,OAAO,CAAC;MACjCoB,QAAQ,EAAE,IAAI,CAACR,cAAc,CAACC,MAAM,CAAC;MACrCL,MAAM,EAAE;IACZ,CAAC;IACD,MAAMa,cAAc,GAAG,IAAI,CAACC,WAAW,CAACH,MAAM,EAAEnB,OAAO,CAAC;IACxD,WAAW,MAAMuB,gBAAgB,IAAIF,cAAc,EAAE;MACjD,MAAMG,IAAI,GAAGC,IAAI,CAACC,KAAK,CAACH,gBAAgB,CAAC;MACzC,MAAMI,MAAM,GAAGH,IAAI,CAACI,OAAO,GAAG,CAAC,CAAC;MAChC,IAAI,CAACD,MAAM,EAAE;QACT;MACJ;MACA,MAAM;QAAEE;MAAM,CAAC,GAAGF,MAAM;MACxB,MAAMG,eAAe,GAAG,IAAI9E,eAAe,CAAC;QACxC+E,IAAI,EAAEF,KAAK,CAACb,OAAO,IAAI;MAC3B,CAAC,CAAC;MACF,MAAMc,eAAe;MACrB;MACA,KAAKZ,UAAU,EAAEc,iBAAiB,CAACF,eAAe,CAACC,IAAI,IAAI,EAAE,CAAC;IAClE;EACJ;EACAT,WAAWA,CAACW,OAAO,EAAEjC,OAAO,EAAE;IAC1B,IAAIkC,IAAI,GAAG,KAAK;IAChB,MAAM1B,MAAM,GAAG,IAAI2B,eAAe,CAAC,CAAC;IACpC,MAAMC,MAAM,GAAG5B,MAAM,CAAC7B,QAAQ,CAAC0D,SAAS,CAAC,CAAC;IAC1C,MAAMC,QAAQ,GAAGhF,6BAA6B,CAACkD,MAAM,CAAC+B,QAAQ,CAAC;IAC/D;IACA,IAAIC,GAAG;IACP,IAAI,CAACC,mBAAmB,CAACR,OAAO,EAAE;MAC9B,GAAGjC,OAAO;MACV0C,OAAO,EAAEzF,YAAY;MACrB0F,YAAY,EAAE,QAAQ;MACtBC,SAAS,EAAGC,KAAK,IAAK;QAClB,IAAIX,IAAI,EACJ;QACJ,IAAIW,KAAK,CAACrB,IAAI,EAAEsB,IAAI,GAAG,CAAC,KAAK,QAAQ,EAAE;UACnCZ,IAAI,GAAG,IAAI;UACX;UACA,KAAKE,MAAM,CAACW,KAAK,CAAC,CAAC;QACvB,CAAC,MACI;UACD,MAAMvB,IAAI,GAAGC,IAAI,CAACC,KAAK,CAACmB,KAAK,CAACrB,IAAI,CAAC;UACnC,IAAIA,IAAI,CAACwB,KAAK,EAAE;YACZd,IAAI,GAAG,IAAI;YACX,MAAMV,IAAI,CAACwB,KAAK;UACpB;UACA;UACA,KAAKZ,MAAM,CAACa,KAAK,CAACJ,KAAK,CAACrB,IAAI,CAAC;QACjC;MACJ;IACJ,CAAC,CAAC,CAAC0B,KAAK,CAAEF,KAAK,IAAK;MAChB,IAAI,CAACd,IAAI,EAAE;QACPM,GAAG,GAAGQ,KAAK;QACXd,IAAI,GAAG,IAAI;QACX;QACA,KAAKE,MAAM,CAACW,KAAK,CAAC,CAAC;MACvB;IACJ,CAAC,CAAC;IACF,OAAO;MACH,MAAMI,IAAIA,CAAA,EAAG;QACT,MAAMC,KAAK,GAAG,MAAMd,QAAQ,CAACa,IAAI,CAAC,CAAC;QACnC,IAAIX,GAAG,EAAE;UACL,MAAMA,GAAG;QACb;QACA,OAAOY,KAAK;MAChB,CAAC;MACD,CAACC,MAAM,CAACC,aAAa,IAAI;QACrB,OAAO,IAAI;MACf;IACJ,CAAC;EACL;EACA;EACA,MAAMC,KAAKA,CAAC1C,MAAM,EAAEb,OAAO,EAAEkB,UAAU,EAAE;IACrC,MAAMC,MAAM,GAAG,IAAI,CAACpB,gBAAgB,CAACC,OAAO,CAAC;IAC7C,MAAMwB,IAAI,GAAGL,MAAM,CAACX,MAAM,GACpB,MAAM,IAAIgD,OAAO,CAAC,CAACC,OAAO,EAAEC,MAAM,KAAK;MACrC,IAAIC,QAAQ;MACZ,IAAIC,QAAQ,GAAG,KAAK;MACpB,IAAIC,QAAQ,GAAG,KAAK;MACpB,IAAI,CAACpB,mBAAmB,CAAC;QACrB,GAAGtB,MAAM;QACTC,QAAQ,EAAE,IAAI,CAACR,cAAc,CAACC,MAAM;MACxC,CAAC,EAAE;QACCiD,MAAM,EAAE9D,OAAO,CAAC8D,MAAM;QACtB,GAAG9D,OAAO,CAACA,OAAO;QAClB0C,OAAO,EAAEzF,YAAY;QACrB0F,YAAY,EAAE,QAAQ;QACtBC,SAAS,EAAGC,KAAK,IAAK;UAClB,IAAIA,KAAK,CAACrB,IAAI,EAAEsB,IAAI,GAAG,CAAC,KAAK,QAAQ,EAAE;YACnC,IAAIe,QAAQ,IAAID,QAAQ,EAAE;cACtB;YACJ;YACAC,QAAQ,GAAG,IAAI;YACfJ,OAAO,CAACE,QAAQ,CAAC;UACrB,CAAC,MACI;YACD,MAAMnC,IAAI,GAAGC,IAAI,CAACC,KAAK,CAACmB,KAAK,CAACrB,IAAI,CAAC;YACnC,IAAIA,IAAI,EAAEwB,KAAK,EAAE;cACb,IAAIY,QAAQ,EAAE;gBACV;cACJ;cACAA,QAAQ,GAAG,IAAI;cACfF,MAAM,CAAClC,IAAI,CAACwB,KAAK,CAAC;cAClB;YACJ;YACA,MAAMlC,OAAO,GAAGU,IAAI;YACpB;YACA,IAAI,CAACmC,QAAQ,EAAE;cACXA,QAAQ,GAAG;gBACPI,EAAE,EAAEjD,OAAO,CAACiD,EAAE;gBACdC,MAAM,EAAElD,OAAO,CAACkD,MAAM;gBACtBC,OAAO,EAAEnD,OAAO,CAACmD,OAAO;gBACxBhE,KAAK,EAAEa,OAAO,CAACb,KAAK;gBACpB2B,OAAO,EAAE;cACb,CAAC;YACL;YACA;YACA,KAAK,MAAMsC,IAAI,IAAIpD,OAAO,CAACc,OAAO,EAAE;cAChC,IAAIsC,IAAI,IAAI,IAAI,EAAE;gBACd,IAAIvC,MAAM,GAAGgC,QAAQ,CAAC/B,OAAO,CAACuC,IAAI,CAAEC,CAAC,IAAKA,CAAC,CAACC,KAAK,KAAKH,IAAI,CAACG,KAAK,CAAC;gBACjE,IAAI,CAAC1C,MAAM,EAAE;kBACTA,MAAM,GAAG;oBACL0C,KAAK,EAAEH,IAAI,CAACG,KAAK;oBACjBC,aAAa,EAAEJ,IAAI,CAACI,aAAa,IAAI/D;kBACzC,CAAC;kBACDoD,QAAQ,CAAC/B,OAAO,CAAC2C,IAAI,CAAC5C,MAAM,CAAC;gBACjC;gBACA,IAAI,CAACA,MAAM,CAACb,OAAO,EAAE;kBACjBa,MAAM,CAACb,OAAO,GAAG;oBACbC,IAAI,EAAEmD,IAAI,CAACrC,KAAK,EACVd,IAAI;oBACVC,OAAO,EAAEkD,IAAI,CAACrC,KAAK,EAAEb,OAAO,IAAI;kBACpC,CAAC;gBACL;gBACAW,MAAM,CAACb,OAAO,CAACE,OAAO,IAAIkD,IAAI,CAACrC,KAAK,EAAEb,OAAO,IAAI,EAAE;gBACnD;gBACA,KAAKE,UAAU,EAAEc,iBAAiB,CAACkC,IAAI,CAACrC,KAAK,EAAEb,OAAO,IAAI,EAAE,EAAE;kBAC1DH,MAAM,EAAEb,OAAO,CAACwE,WAAW,IAAI,CAAC;kBAChCC,UAAU,EAAEP,IAAI,CAACG;gBACrB,CAAC,CAAC;cACN;YACJ;YACA;YACA,IAAI,CAACR,QAAQ,IACT,CAACD,QAAQ,IACT9C,OAAO,CAACc,OAAO,CAAC8C,KAAK,CAAEN,CAAC,IAAKA,CAAC,CAACE,aAAa,IAAI,IAAI,CAAC,EAAE;cACvDT,QAAQ,GAAG,IAAI;cACfJ,OAAO,CAACE,QAAQ,CAAC;YACrB;UACJ;QACJ;MACJ,CAAC,CAAC,CAACT,KAAK,CAAEF,KAAK,IAAK;QAChB,IAAI,CAACY,QAAQ,EAAE;UACXA,QAAQ,GAAG,IAAI;UACfF,MAAM,CAACV,KAAK,CAAC;QACjB;MACJ,CAAC,CAAC;IACN,CAAC,CAAC,GACA,MAAM,IAAI,CAACP,mBAAmB,CAAC;MAC7B,GAAGtB,MAAM;MACTC,QAAQ,EAAE,IAAI,CAACR,cAAc,CAACC,MAAM;IACxC,CAAC,EAAE;MACCiD,MAAM,EAAE9D,OAAO,CAAC8D,MAAM;MACtB,GAAG9D,OAAO,CAACA;IACf,CAAC,CAAC;IACN,OAAOwB,IAAI,CAACI,OAAO,CAAC,CAAC,CAAC,CAACd,OAAO,EAAEE,OAAO,IAAI,EAAE;EACjD;EACA;EACA,MAAMyB,mBAAmBA,CAACR,OAAO,EAAEjC,OAAO,EAAE;IACxC,IAAI,CAAC,IAAI,CAAC2E,MAAM,EAAE;MACd,MAAMC,oBAAoB,GAAG;QACzBzG,4BAA4B,EAAE,IAAI,CAACA,4BAA4B;QAC/DD,0BAA0B,EAAE,IAAI,CAACA,0BAA0B;QAC3DL,iBAAiB,EAAE,IAAI,CAACA,iBAAiB;QACzCkB,mBAAmB,EAAE,IAAI,CAACA,mBAAmB;QAC7C8F,QAAQ,EAAE,IAAI,CAAChF,YAAY,CAACgF;MAChC,CAAC;MACD,MAAMC,QAAQ,GAAG5H,WAAW,CAAC0H,oBAAoB,CAAC;MAClD,MAAM/E,YAAY,GAAG,IAAI/C,aAAa,CAAC;QACnC,GAAG,IAAI,CAAC+C,YAAY;QACpBgF,QAAQ,EAAEC,QAAQ;QAClBC,WAAW,EAAE;UACT7F,OAAO,EAAE,IAAI,CAACA,OAAO;UACrB,GAAG,IAAI,CAACW,YAAY,CAACkF;QACzB;MACJ,CAAC,CAAC;MACF,IAAI,CAACJ,MAAM,GAAG,IAAI5H,SAAS,CAAC8C,YAAY,CAAC;IAC7C;IACA,MAAMmF,YAAY,GAAG;MACjBtC,OAAO,EAAEtF,MAAM,CAAC,CAAC,GAAGmD,SAAS,GAAGtD,YAAY;MAC5C,GAAG,IAAI,CAAC4C,YAAY,CAACkF,WAAW;MAChC,GAAG/E;IACP,CAAC;IACD,IAAI,IAAI,CAACnC,iBAAiB,EAAE;MACxBmH,YAAY,CAACC,OAAO,GAAG;QACnB,SAAS,EAAE,IAAI,CAACpH,iBAAiB;QACjC,GAAGmH,YAAY,CAACC;MACpB,CAAC;MACDD,YAAY,CAAC7D,MAAM,GAAG;QAClB,aAAa,EAAE,IAAI,CAAClD,qBAAqB;QACzC,GAAG+G,YAAY,CAAC7D;MACpB,CAAC;IACL;IACA,OAAO,IAAI,CAAC+D,MAAM,CACbC,IAAI,CAAC,IAAI,CAACR,MAAM,CAACS,oBAAoB,CAACC,IAAI,CAAC,IAAI,CAACV,MAAM,CAAC,EAAE1C,OAAO,EAAE+C,YAAY,CAAC,CAC/EM,IAAI,CAAEC,GAAG,IAAKA,GAAG,CAAC/D,IAAI,CAAC;EAChC;EACAgE,QAAQA,CAAA,EAAG;IACP,OAAO,QAAQ;EACnB;AACJ;AACA;AACA;AACA;AACA,OAAO,MAAMC,qBAAqB,SAASjI,UAAU,CAAC;EAClD,IAAIG,UAAUA,CAAA,EAAG;IACb,OAAO;MACH+H,iBAAiB,EAAE;IACvB,CAAC;EACL;EACAtH,WAAWA,CAACC,MAAM,EAAE;IAChB,KAAK,CAACA,MAAM,CAAC;IACbE,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,iBAAiB,EAAE;MAC3CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,mBAAmB,EAAE;MAC7CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,QAAQ,EAAE;MAClCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,qBAAqB,EAAE;MAC/CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACF,IAAI,CAAC+G,MAAM,GAAGtH,MAAM,EAAEsH,MAAM,IAAI,EAAE;IAClC,IAAI,CAACC,mBAAmB,GAAGvH,MAAM,EAAEuH,mBAAmB,IAAI,KAAK;IAC/D,IAAI,CAACF,iBAAiB,GAClBrH,MAAM,EAAEqH,iBAAiB,IACrBvI,sBAAsB,CAAC,qBAAqB,CAAC;IACrD,IAAI,CAAC,IAAI,CAACuI,iBAAiB,EAAE;MACzB,MAAM,IAAI7G,KAAK,CAAC,6BAA6B,CAAC;IAClD;EACJ;EACA,MAAM4D,mBAAmBA,CAACR,OAAO,EAAEjC,OAAO,EAAE;IACxC,IAAIiC,OAAO,CAACzB,MAAM,EAAE;MAChB,OAAO,KAAK,CAACiC,mBAAmB,CAACR,OAAO,EAAEjC,OAAO,CAAC;IACtD;IACA,MAAM2D,QAAQ,GAAG,MAAM,KAAK,CAAClB,mBAAmB,CAACR,OAAO,CAAC;IACzD,OAAO0B,QAAQ;EACnB;EACA,MAAMkC,SAASA,CAACC,OAAO,EAAE9F,OAAO,EAAEkB,UAAU,EAAE;IAC1C,IAAIS,MAAM;IACV,MAAMoE,WAAW,GAAG,MAAMvC,OAAO,CAACwC,GAAG,CAACF,OAAO,CAACG,GAAG,CAAC,MAAOpF,MAAM,IAAK;MAChE,MAAMqF,gBAAgB,GAAGC,IAAI,CAACC,GAAG,CAAC,CAAC;MACnC,MAAMrE,IAAI,GAAG,MAAM,IAAI,CAACwB,KAAK,CAAC1C,MAAM,EAAEb,OAAO,EAAEkB,UAAU,CAAC;MAC1D,MAAMmF,cAAc,GAAGF,IAAI,CAACC,GAAG,CAAC,CAAC;MACjCzE,MAAM,GAAG,CAAC;QAAEI;MAAK,CAAC,CAAC;MACnB,MAAMuE,UAAU,GAAG;QACfvE;MACJ,CAAC;MACD,MAAMwE,mBAAmB,GAAG,MAAMlJ,uBAAuB,CAAC,IAAI,CAAC6H,MAAM,EAAE,iCAAiC,EAAE,CAACrE,MAAM,CAAC,EAAE,IAAI,CAACJ,kBAAkB,CAAC,CAAC,EAAE,IAAI,CAACkF,MAAM,EAAEW,UAAU,EAAEJ,gBAAgB,EAAEG,cAAc,EAAE,IAAI,CAACX,iBAAiB,CAAC;MACjO,IAAI,IAAI,CAACE,mBAAmB,KAAK,IAAI,IACjCW,mBAAmB,CAACC,OAAO,KAAK,IAAI,EAAE;QACtC7E,MAAM,CAAC,CAAC,CAAC,CAAC8E,cAAc,GAAG;UACvBC,oBAAoB,EAAEH,mBAAmB,CAACI;QAC9C,CAAC;MACL;MACA,OAAOhF,MAAM;IACjB,CAAC,CAAC,CAAC;IACH,OAAO;MAAEoE;IAAY,CAAC;EAC1B;AACJ"},"metadata":{},"sourceType":"module","externalDependencies":[]}