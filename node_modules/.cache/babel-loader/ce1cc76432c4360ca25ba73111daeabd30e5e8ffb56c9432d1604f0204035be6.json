{"ast":null,"code":"import { ChatOpenAI } from \"langchain/chat_models/openai\";\nimport { HumanMessage, ChatMessage, SystemMessage } from \"langchain/schema\";\nclass LangchainProcessor {\n  constructor(createChatBotMessage) {\n    this.createChatBotMessage = createChatBotMessage;\n  }\n  async process(newMessage, allMessages) {\n    const chat = new ChatOpenAI({\n      temperature: 0,\n      openAIApiKey: process.env.REACT_APP_OPEN_AI_API_KEY\n    });\n    try {\n      // Convert all previous messages to the format expected by ChatOpenAI\n      const formattedMessages = allMessages.map(msg => {\n        if (msg.type === \"user\") {\n          return new HumanMessage(msg.content);\n        } else if (msg.type === \"bot\") {\n          // We're assuming that bot messages should be treated as SystemMessages.\n          // If that's not the case, adjust accordingly.\n          return new SystemMessage(msg.content);\n        } else {\n          // For other message types, like \"system\" or custom roles, \n          // you can use ChatMessage with the appropriate role.\n          return new ChatMessage(msg.content, msg.type);\n        }\n      });\n\n      // Add the new human message to the list\n      formattedMessages.push(new HumanMessage(newMessage));\n      const result = await chat.predictMessages(formattedMessages);\n\n      // Extract the content from the AIMessage\n      const botResponseContent = result.content;\n\n      // Add the AIMessage to allMessages\n      allMessages.push({\n        type: \"bot\",\n        content: botResponseContent\n      });\n      return botResponseContent;\n    } catch (error) {\n      console.error(\"Error processing message with OpenAI:\", error);\n      return \"Sorry, I faced an error processing your message.\";\n    }\n  }\n}\nexport default LangchainProcessor;","map":{"version":3,"names":["ChatOpenAI","HumanMessage","ChatMessage","SystemMessage","LangchainProcessor","constructor","createChatBotMessage","process","newMessage","allMessages","chat","temperature","openAIApiKey","env","REACT_APP_OPEN_AI_API_KEY","formattedMessages","map","msg","type","content","push","result","predictMessages","botResponseContent","error","console"],"sources":["/Users/idasilfverskiold/gptSandbox/reactlangchain/sandbox/src/components/LangchainProcessor.js"],"sourcesContent":["import { ChatOpenAI } from \"langchain/chat_models/openai\";\nimport { HumanMessage, ChatMessage, SystemMessage } from \"langchain/schema\";\n\nclass LangchainProcessor {\n    constructor(createChatBotMessage) {\n        this.createChatBotMessage = createChatBotMessage;\n    }\n\n    async process(newMessage, allMessages) {\n        const chat = new ChatOpenAI({\n            temperature: 0,\n            openAIApiKey: process.env.REACT_APP_OPEN_AI_API_KEY\n        });\n\n        try {\n            // Convert all previous messages to the format expected by ChatOpenAI\n            const formattedMessages = allMessages.map(msg => {\n                if (msg.type === \"user\") {\n                    return new HumanMessage(msg.content);\n                } else if (msg.type === \"bot\") {\n                    // We're assuming that bot messages should be treated as SystemMessages.\n                    // If that's not the case, adjust accordingly.\n                    return new SystemMessage(msg.content);\n                } else {\n                    // For other message types, like \"system\" or custom roles, \n                    // you can use ChatMessage with the appropriate role.\n                    return new ChatMessage(msg.content, msg.type);\n                }\n            });\n\n            // Add the new human message to the list\n            formattedMessages.push(new HumanMessage(newMessage));\n\n            const result = await chat.predictMessages(formattedMessages);\n\n            // Extract the content from the AIMessage\n            const botResponseContent = result.content;\n\n            // Add the AIMessage to allMessages\n            allMessages.push({\n                type: \"bot\",\n                content: botResponseContent\n            });\n\n            return botResponseContent;\n\n        } catch (error) {\n            console.error(\"Error processing message with OpenAI:\", error);\n            return \"Sorry, I faced an error processing your message.\";\n        }\n    }\n}\n\nexport default LangchainProcessor;\n"],"mappings":"AAAA,SAASA,UAAU,QAAQ,8BAA8B;AACzD,SAASC,YAAY,EAAEC,WAAW,EAAEC,aAAa,QAAQ,kBAAkB;AAE3E,MAAMC,kBAAkB,CAAC;EACrBC,WAAWA,CAACC,oBAAoB,EAAE;IAC9B,IAAI,CAACA,oBAAoB,GAAGA,oBAAoB;EACpD;EAEA,MAAMC,OAAOA,CAACC,UAAU,EAAEC,WAAW,EAAE;IACnC,MAAMC,IAAI,GAAG,IAAIV,UAAU,CAAC;MACxBW,WAAW,EAAE,CAAC;MACdC,YAAY,EAAEL,OAAO,CAACM,GAAG,CAACC;IAC9B,CAAC,CAAC;IAEF,IAAI;MACA;MACA,MAAMC,iBAAiB,GAAGN,WAAW,CAACO,GAAG,CAACC,GAAG,IAAI;QAC7C,IAAIA,GAAG,CAACC,IAAI,KAAK,MAAM,EAAE;UACrB,OAAO,IAAIjB,YAAY,CAACgB,GAAG,CAACE,OAAO,CAAC;QACxC,CAAC,MAAM,IAAIF,GAAG,CAACC,IAAI,KAAK,KAAK,EAAE;UAC3B;UACA;UACA,OAAO,IAAIf,aAAa,CAACc,GAAG,CAACE,OAAO,CAAC;QACzC,CAAC,MAAM;UACH;UACA;UACA,OAAO,IAAIjB,WAAW,CAACe,GAAG,CAACE,OAAO,EAAEF,GAAG,CAACC,IAAI,CAAC;QACjD;MACJ,CAAC,CAAC;;MAEF;MACAH,iBAAiB,CAACK,IAAI,CAAC,IAAInB,YAAY,CAACO,UAAU,CAAC,CAAC;MAEpD,MAAMa,MAAM,GAAG,MAAMX,IAAI,CAACY,eAAe,CAACP,iBAAiB,CAAC;;MAE5D;MACA,MAAMQ,kBAAkB,GAAGF,MAAM,CAACF,OAAO;;MAEzC;MACAV,WAAW,CAACW,IAAI,CAAC;QACbF,IAAI,EAAE,KAAK;QACXC,OAAO,EAAEI;MACb,CAAC,CAAC;MAEF,OAAOA,kBAAkB;IAE7B,CAAC,CAAC,OAAOC,KAAK,EAAE;MACZC,OAAO,CAACD,KAAK,CAAC,uCAAuC,EAAEA,KAAK,CAAC;MAC7D,OAAO,kDAAkD;IAC7D;EACJ;AACJ;AAEA,eAAepB,kBAAkB"},"metadata":{},"sourceType":"module","externalDependencies":[]}