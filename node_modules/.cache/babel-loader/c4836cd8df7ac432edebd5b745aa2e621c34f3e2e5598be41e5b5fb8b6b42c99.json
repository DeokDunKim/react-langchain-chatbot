{"ast":null,"code":"import { ChatOpenAI } from \"langchain/chat_models/openai\";\nimport { HumanMessage, ChatMessage, SystemMessage } from \"langchain/schema\";\nclass LangchainProcessor {\n  constructor(createChatBotMessage) {\n    this.createChatBotMessage = createChatBotMessage;\n  }\n  async process(newMessage, allMessages) {\n    const chat = new ChatOpenAI({\n      temperature: 0,\n      openAIApiKey: process.env.REACT_APP_OPEN_AI_API_KEY\n    });\n    try {\n      console.log(allMessages);\n      // Convert all previous messages to the format expected by ChatOpenAI\n      const formattedMessages = allMessages.map(msg => {\n        if (msg.type === \"user\") {\n          return new HumanMessage(msg.content);\n        } else if (msg.type === \"bot\") {\n          // We're assuming that bot messages should be treated as SystemMessages.\n          // If that's not the case, adjust accordingly.\n          return new SystemMessage(msg.content);\n        } else {\n          // For other message types, like \"system\" or custom roles, \n          // you can use ChatMessage with the appropriate role.\n          return new ChatMessage(msg.content, msg.type);\n        }\n      });\n      console.log(formattedMessages);\n\n      // Add the new human message to the list\n      // formattedMessages.push(new HumanMessage(newMessage));\n\n      // const result = await chat.predictMessages(formattedMessages);\n\n      // // Extract the content from the AIMessage\n      // const botResponseContent = result.content;\n\n      // // Add the AIMessage to allMessages\n      // allMessages.push({\n      //     type: \"bot\",\n      //     content: botResponseContent\n      // });\n\n      // return botResponseContent;\n    } catch (error) {\n      console.error(\"Error processing message with OpenAI:\", error);\n      return \"Sorry, I faced an error processing your message.\";\n    }\n  }\n}\nexport default LangchainProcessor;","map":{"version":3,"names":["ChatOpenAI","HumanMessage","ChatMessage","SystemMessage","LangchainProcessor","constructor","createChatBotMessage","process","newMessage","allMessages","chat","temperature","openAIApiKey","env","REACT_APP_OPEN_AI_API_KEY","console","log","formattedMessages","map","msg","type","content","error"],"sources":["/Users/idasilfverskiold/gptSandbox/reactlangchain/sandbox/src/components/LangchainProcessor.js"],"sourcesContent":["import { ChatOpenAI } from \"langchain/chat_models/openai\";\nimport { HumanMessage, ChatMessage, SystemMessage } from \"langchain/schema\";\n\nclass LangchainProcessor {\n    constructor(createChatBotMessage) {\n        this.createChatBotMessage = createChatBotMessage;\n    }\n\n    async process(newMessage, allMessages) {\n        const chat = new ChatOpenAI({\n            temperature: 0,\n            openAIApiKey: process.env.REACT_APP_OPEN_AI_API_KEY\n        });\n\n        try {\n            console.log(allMessages)\n            // Convert all previous messages to the format expected by ChatOpenAI\n            const formattedMessages = allMessages.map(msg => {\n                if (msg.type === \"user\") {\n                    return new HumanMessage(msg.content);\n                } else if (msg.type === \"bot\") {\n                    // We're assuming that bot messages should be treated as SystemMessages.\n                    // If that's not the case, adjust accordingly.\n                    return new SystemMessage(msg.content);\n                } else {\n                    // For other message types, like \"system\" or custom roles, \n                    // you can use ChatMessage with the appropriate role.\n                    return new ChatMessage(msg.content, msg.type);\n                }\n            });\n\n            console.log(formattedMessages);\n\n            // Add the new human message to the list\n            // formattedMessages.push(new HumanMessage(newMessage));\n\n            // const result = await chat.predictMessages(formattedMessages);\n\n            // // Extract the content from the AIMessage\n            // const botResponseContent = result.content;\n\n            // // Add the AIMessage to allMessages\n            // allMessages.push({\n            //     type: \"bot\",\n            //     content: botResponseContent\n            // });\n\n            // return botResponseContent;\n\n        } catch (error) {\n            console.error(\"Error processing message with OpenAI:\", error);\n            return \"Sorry, I faced an error processing your message.\";\n        }\n    }\n}\n\nexport default LangchainProcessor;\n"],"mappings":"AAAA,SAASA,UAAU,QAAQ,8BAA8B;AACzD,SAASC,YAAY,EAAEC,WAAW,EAAEC,aAAa,QAAQ,kBAAkB;AAE3E,MAAMC,kBAAkB,CAAC;EACrBC,WAAWA,CAACC,oBAAoB,EAAE;IAC9B,IAAI,CAACA,oBAAoB,GAAGA,oBAAoB;EACpD;EAEA,MAAMC,OAAOA,CAACC,UAAU,EAAEC,WAAW,EAAE;IACnC,MAAMC,IAAI,GAAG,IAAIV,UAAU,CAAC;MACxBW,WAAW,EAAE,CAAC;MACdC,YAAY,EAAEL,OAAO,CAACM,GAAG,CAACC;IAC9B,CAAC,CAAC;IAEF,IAAI;MACAC,OAAO,CAACC,GAAG,CAACP,WAAW,CAAC;MACxB;MACA,MAAMQ,iBAAiB,GAAGR,WAAW,CAACS,GAAG,CAACC,GAAG,IAAI;QAC7C,IAAIA,GAAG,CAACC,IAAI,KAAK,MAAM,EAAE;UACrB,OAAO,IAAInB,YAAY,CAACkB,GAAG,CAACE,OAAO,CAAC;QACxC,CAAC,MAAM,IAAIF,GAAG,CAACC,IAAI,KAAK,KAAK,EAAE;UAC3B;UACA;UACA,OAAO,IAAIjB,aAAa,CAACgB,GAAG,CAACE,OAAO,CAAC;QACzC,CAAC,MAAM;UACH;UACA;UACA,OAAO,IAAInB,WAAW,CAACiB,GAAG,CAACE,OAAO,EAAEF,GAAG,CAACC,IAAI,CAAC;QACjD;MACJ,CAAC,CAAC;MAEFL,OAAO,CAACC,GAAG,CAACC,iBAAiB,CAAC;;MAE9B;MACA;;MAEA;;MAEA;MACA;;MAEA;MACA;MACA;MACA;MACA;;MAEA;IAEJ,CAAC,CAAC,OAAOK,KAAK,EAAE;MACZP,OAAO,CAACO,KAAK,CAAC,uCAAuC,EAAEA,KAAK,CAAC;MAC7D,OAAO,kDAAkD;IAC7D;EACJ;AACJ;AAEA,eAAelB,kBAAkB"},"metadata":{},"sourceType":"module","externalDependencies":[]}